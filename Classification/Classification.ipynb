{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7267036",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "#!pip install tensorflowjs\n",
    "!pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a8826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, f1_score, recall_score, precision_score, accuracy_score\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb80556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f72cba",
   "metadata": {},
   "source": [
    "# Setting a seed\n",
    "Setting a seed so we can guarantee the same results no matter how many times we run the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba8897",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1305\n",
    "np.random.seed(seed)\n",
    "set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dfc656",
   "metadata": {},
   "source": [
    "# Setting the image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eacbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = pathlib.Path(\"./data/train\")\n",
    "val_path = pathlib.Path('./data/val')\n",
    "test_path = pathlib.Path('./data/test')\n",
    "\n",
    "train_data = list(train_path.glob('*/*.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "subpath = list(train_path.glob('*'))\n",
    "species = []\n",
    "boxplot_data = []\n",
    "\n",
    "for i in range (0, len(subpath)):\n",
    "    species.append(subpath[i].name)\n",
    "    boxplot_data.append([subpath[i].name, len(os.listdir(subpath[i]))])\n",
    "\n",
    "species.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419fc3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_files = pd.DataFrame(columns=['Species', 'No of files'], data=boxplot_data)\n",
    "count_more_than_300 = 0\n",
    "list_of_species_to_keep = []\n",
    "\n",
    "for index, row in no_of_files.iterrows():\n",
    "    if row['No of files'] >= 300:\n",
    "        count_more_than_300 += 1\n",
    "        list_of_species_to_keep.append(row['Species'])\n",
    "        \n",
    "list_of_species_to_keep        \n",
    "count_more_than_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7519c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "plot_species = no_of_files['Species']\n",
    "plot_numbers = no_of_files['No of files']\n",
    "ax.bar(plot_species,plot_numbers)\n",
    "plt.xticks(rotation = -90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c24f70",
   "metadata": {},
   "source": [
    "# Setting image height and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e4191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (150, 100) # (height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30365e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    seed=1337,\n",
    "    image_size=image_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_path,\n",
    "    seed=1337,\n",
    "    image_size=image_size\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_path,\n",
    "    seed=1337,\n",
    "    image_size=image_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9456b6",
   "metadata": {},
   "source": [
    "# Setting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# adding layers\n",
    "model.add(Conv2D(25, (9, 9), input_shape=(image_size[0], image_size[1], 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Conv2D(50, (9, 9), input_shape=(image_size[0], image_size[1], 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(len(species), activation='softmax'))\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b9ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb741c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a86fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(train_ds, validation_data=val_ds, epochs=epochs) #batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fafe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = result\n",
    "\n",
    "acc_train = history.history['accuracy']\n",
    "acc_val = history.history['val_accuracy']\n",
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(17, 2))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(epochs), acc_train, label='Train data')\n",
    "plt.plot(range(epochs), acc_val, label='Validation data')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(epochs), loss_train, label='Train data')\n",
    "plt.plot(range(epochs), loss_val, label='Validation data')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(val_ds, verbose=0)\n",
    "print('Val loss:', scores[0])\n",
    "print('Val accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_ds)\n",
    "#print('Predictions:\\n', predictions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319dbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predictions:\\n', predictions[np.argmax(tf.nn.softmax(predictions[0]))])\n",
    "test_scores = model.evaluate(test_ds, verbose=0)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20338ccc",
   "metadata": {},
   "source": [
    "# Saving the model\n",
    "Firstly we save it in the default format and then the HDF5 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./exported_models/botaniai_model_v1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./exported_models/botaniai_model_v1.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3dfcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"./exported_models/botaniai_model_v1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./exported_models/botaniai_model_weights_v1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3162058",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, './tensorflowjs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
